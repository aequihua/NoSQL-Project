text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
print(paste("hashtag =", hashtag))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
print(paste("hashtag =", hashtag))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2"), main="TEST"))
dev.off();
}
}
plot13()
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("hashtag =", hashtag))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2"))
dev.off();
}
}
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("hashtag =", hashtag))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
plot13()
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", hashtag))
text(x=0.5, y=0.5, paste("#", "hashtag"))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
layout(matrix(c(1, 2), nrow=2), heights=c(1, 5))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", "hashtag"))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", "hashtag"))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", hashtag))
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
plot13()
?text
text(x=0.5, y=0.5, paste("#", hashtag), cex=2)
text(x=0.5, y=0.5, paste("#", "hashtag"), cex=2)
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", "hashtag"), cex=2)
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", "hashtag"), cex=2)
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", hashtag), cex=2)
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
plot13()
?paste
#wordcloud por hashtag
plot13 <- function(hashtag = "YaMeCanse") {
library(XML)
library(ggplot2)
library(lubridate)
library(tm)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$hashtag == hashtag,]
text <- data$text
if (length(text) > 0) {
text <- as.character(text)
text <- strsplit(text, " ")
text <- unlist(text)
#text <- tolower(text)
text <- text[text != "RT"] #elimina RT
text <- text[!(grepl("#", text) | grepl("@", text))] #elimina hashtag y menciones
text <- text[!grepl("http", text)] #elimina url
text <- unlist(strsplit(text, "[[:punct:][:space:]]")) #elimina puntuacion
text <- text[!(text %in% stopwords("spanish"))] #elimina stopwords
text <- text[text != ""] #elimina palabras vacias
text <- data.frame(text, replicate(length(text), 1))
names(text) <- c("text", "count")
count <- aggregate(text[, 'count'], by = list(text$text), FUN = sum)
names(count) <- c("text", "count")
count <- count[order(count$count, decreasing = TRUE),]
png(filename = "wordcloud.png", width = 680, height = 680, units = "px")
layout(matrix(c(1, 2), nrow=2), heights=c(.2, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, paste("#", hashtag, sep=""), cex=2)
print(wordcloud(count$text,count$count, scale=c(3,.3),min.freq=1,
max.words=500, random.order=FALSE, rot.per=.15,
colors=brewer.pal(8,"Dark2")))
dev.off();
}
}
plot13()
plot13("Ayotzinapa")
plot13("20NovMx")
plot4(10)
plot4(top=10)
#top n de tweets agrupados por hashtag
plot4 <- function(date = Sys.Date(), top = 5) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$hashtag), FUN = sum)
names(tweets) <- c("hashtag", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
png(filename = "plot4.png", width = 680, height = 680, units = "px")
print(qplot(hashtag, count, data=head(tweets, n=top), fill=hashtag,
main=paste("Top", top, "tweets en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Hashtag", ylab="Total") + geom_bar(stat = "identity"))
dev.off();
}
plot4(top=10)
plot4()
plot4("2014-11-20")
plot4("2014-11-21")
plot4("2014-11-23")
plot4("2014-11-20")
plot13("AMAs")
plot4("2014-11-24")
#top n de tweets agrupados por hashtag por hora
plot5 <- function(date = Sys.Date(), ntop = 3) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
times <- c(hms("12:00:00"), hms("13:00:00"), hms("14:00:00"), hms("15:00:00"), hms("16:00:00"), hms("17:00:00"), hms("18:00:00"), hms("19:00:00"), hms("20:00:00"), hms("21:00:00"), hms("22:00:00"), hms("23:00:00"), hms("00:00:00"), hms("01:00:00"), hms("02:00:00"), hms("03:00:00"), hms("04:00:00"), hms("05:00:00"), hms("06:00:00"), hms("07:00:00"), hms("08:00:00"), hms("09:00:00"), hms("10:00:00"), hms("11:00:00"))
data$time <- cut(hour(data$createdat) + minute(data$createdat)/60, hour(times))
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$hashtag), FUN = sum)
names(tweets) <- c("hashtag", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"hashtag"], n=ntop)
png(filename = "plot5.png", width = 680, height = 680, units = "px")
print(qplot(time, data=data[data$hashtag %in% top,], facets=hashtag ~ ., fill=hashtag,
main=paste("Top", ntop, "tweets por hora en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Hora", ylab="Total"))
dev.off();
}
plot5()
?qplot
#top n de tweets agrupados por hashtag por hora
plot5 <- function(date = Sys.Date(), ntop = 3) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
times <- c(hms("12:00:00"), hms("13:00:00"), hms("14:00:00"), hms("15:00:00"), hms("16:00:00"), hms("17:00:00"), hms("18:00:00"), hms("19:00:00"), hms("20:00:00"), hms("21:00:00"), hms("22:00:00"), hms("23:00:00"), hms("00:00:00"), hms("01:00:00"), hms("02:00:00"), hms("03:00:00"), hms("04:00:00"), hms("05:00:00"), hms("06:00:00"), hms("07:00:00"), hms("08:00:00"), hms("09:00:00"), hms("10:00:00"), hms("11:00:00"))
data$time <- cut(hour(data$createdat) + minute(data$createdat)/60, hour(times))
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$hashtag), FUN = sum)
names(tweets) <- c("hashtag", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"hashtag"], n=ntop)
png(filename = "plot5.png", width = 680, height = 680, units = "px")
print(qplot(time, data=data[data$hashtag %in% top,], facets=hashtag ~ ., fill=hashtag,
main=paste("Top", ntop, "tweets por hora en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Hora", ylab="Total") + theme(legend.position="none"))
dev.off();
}
?qplot
plot5()
#top n de tweets agrupados por hashtag por dia
plot6 <- function(startDate = "2014-11-19", endDate = Sys.Date(), ntop = 3) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data$date <- as.Date(data$createdat,format = "%Y-%m-%d")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") >= as.Date(startDate) &
as.Date(data$createdat,format = "%Y-%m-%d") <= as.Date(endDate),]
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$hashtag), FUN = sum)
names(tweets) <- c("hashtag", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"hashtag"], n=ntop)
png(filename = "plot6.png", width = 680, height = 680, units = "px")
print(qplot(date, data=data[data$hashtag %in% top,], facets= hashtag ~ ., fill=hashtag,
main=paste("Top", ntop, "tweets por hora entre el dia",
format(as.Date(startDate), format="%d %b %Y"), "y",
format(as.Date(endDate), format="%d %b %Y")),
xlab="Fecha", ylab="Total") + theme(legend.position="none"))
dev.off();
}
plot6()
#top n de tweets por lugar
plot8 <- function(date = Sys.Date(), ntop = 5) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$place != "",]
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$place), FUN = sum)
names(tweets) <- c("place", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"place"], n=ntop)
png(filename = "plot8.png", width = 680, height = 680, units = "px")
print(qplot(place, data=data[data$place %in% top,], fill=place
main=paste("Top", ntop, "tweets por lugar en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Lugar", ylab="Total"))
dev.off();
}
#top n de tweets por lugar
plot8 <- function(date = Sys.Date(), ntop = 5) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$place != "",]
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$place), FUN = sum)
names(tweets) <- c("place", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"place"], n=ntop)
png(filename = "plot8.png", width = 680, height = 680, units = "px")
print(qplot(place, data=data[data$place %in% top,], fill=place,
main=paste("Top", ntop, "tweets por lugar en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Lugar", ylab="Total"))
dev.off();
}
plot8()
#top n de tweets agrupados por lugar por hora
plot9 <- function(date = Sys.Date(), ntop = 3) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$place != "",]
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") == as.Date(date),]
data$count <- 1
times <- c(hms("12:00:00"), hms("13:00:00"), hms("14:00:00"), hms("15:00:00"), hms("16:00:00"), hms("17:00:00"), hms("18:00:00"), hms("19:00:00"), hms("20:00:00"), hms("21:00:00"), hms("22:00:00"), hms("23:00:00"), hms("00:00:00"), hms("01:00:00"), hms("02:00:00"), hms("03:00:00"), hms("04:00:00"), hms("05:00:00"), hms("06:00:00"), hms("07:00:00"), hms("08:00:00"), hms("09:00:00"), hms("10:00:00"), hms("11:00:00"))
data$time <- cut(hour(data$createdat) + minute(data$createdat)/60, hour(times))
tweets <- aggregate(data[, 'count'], by = list(data$place), FUN = sum)
names(tweets) <- c("place", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"place"], n=ntop)
png(filename = "plot9.png", width = 680, height = 680, units = "px")
print(qplot(time, data=data[data$place %in% top,], facets= place ~ ., fill=place,
main=paste("Top", ntop, "tweets por lugar en el dia", format(as.Date(date), format="%d %b %Y")),
xlab="Hora", ylab="Total")+ theme(legend.position="none"))
dev.off();
}
plot9()
#top n de tweets agrupados por lugar por dia
plot10 <- function(startDate = "2014-11-19", endDate = Sys.Date(), ntop = 3) {
library(XML)
library(ggplot2)
library(lubridate)
doc <- xmlTreeParse("./tweet.xml",useInternal=TRUE)
data <- xmlToDataFrame(doc)
data <- data[data$place != "",]
data$createdat <- strptime(data$createdat, "%a %b %d %H:%M:%S %z %Y")
data$date <- as.Date(data$createdat,format = "%Y-%m-%d")
data <- data[as.Date(data$createdat,format = "%Y-%m-%d") >= as.Date(startDate) &
as.Date(data$createdat,format = "%Y-%m-%d") <= as.Date(endDate) ,]
data$count <- 1
tweets <- aggregate(data[, 'count'], by = list(data$place), FUN = sum)
names(tweets) <- c("place", "count")
tweets <- tweets[order(tweets$count, decreasing = TRUE),]
top <- head(tweets[,"place"], n=ntop)
png(filename = "plot10.png", width = 680, height = 680, units = "px")
print(qplot(date, data=data[data$place %in% top,], facets= place ~ ., fill=place,
main=paste("Tweets por lugar entre el dia",
format(as.Date(startDate), format="%d %b %Y"), "y",
format(as.Date(endDate), format="%d %b %Y")),
xlab="Fecha", ylab="Total") + theme(legend.position="none"))
dev.off();
}
plot10()
